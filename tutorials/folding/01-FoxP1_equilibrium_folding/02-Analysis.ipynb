{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folding simulations of FoxP1 - Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This tutorial aims at running and analyzing equilibrium folding simulations for a small protein. Our protein will be the DNA binding domain of the forkhead box P1 (a.k.a. FoxP1) transcription factor protein. \n",
    "\n",
    "The tutorial will be divided into two parts: Production and analysis. \n",
    "\n",
    "The first part is the folding simulation data production and is covered by the production notebook:\n",
    "\n",
    "[01-Analysis Notebook](01-Production.ipynb)\n",
    "\n",
    "This notebook covers the analysis part. To separate both processes, the full simulation data will be automatically downloaded here from its repository to carry out the analysis.\n",
    "\n",
    "We will employ the Markov State Model framework to analyze the simulations. We will use the PyEMMA package for the analysis. Since this is a tutorial on structure-based model (SBM) simulations, we will not go deep into explaining the MSM subject. We recommend to make yourself familiar with the methodology by reading the literature and tutorials available at the:\n",
    "\n",
    "[PyEMMA site](http://emma-project.org/latest/)\n",
    "\n",
    "There is a very complete (at least to the publication date in 2014) book on MSM theory for MD simulations:\n",
    "\n",
    "[An Introduction to Markov State Models and Their Application to Long Timescale Molecular Simulation](https://www.springer.com/gp/book/9789400776050)\n",
    "\n",
    "Many parts of the analysis are very memory consuming, and we recommend processing this notebook having at least 32Gb in RAM available. Also, to avoid loading considerable amounts of information into the RAM while processing the data, we refer some specific calculations to other notebooks within this tutorial folder. It is recommended that you free your memory before running those notebooks. In any case, and for the purpose of this tutorial, the outputs of these notebooks are already in the \"output\" folder, so there is no need to run them, unless you want to review how their code works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the necessary python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import SBMOpenMM library\n",
    "import sbmOpenMM\n",
    "\n",
    "# Import PyEMMA library\n",
    "import pyemma.util.contexts\n",
    "\n",
    "# Import MDtraj library\n",
    "import mdtraj as md\n",
    "\n",
    "# Import numpy \n",
    "import numpy as np\n",
    "\n",
    "# Import ploting tools\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import system and other libraries\n",
    "import os\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sbmOpenMM.datasets.foxp1_folding.download_dataset('simulation_data', dcd_only=True, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the FoxP1 folding simulation data\n",
    "\n",
    "To investigate the folding process of a protein is necessary to generate enough sampling data, especially for the transition-state region, which is the least likely to be populated. Since it is very time-consuming to produce this amount of data, we will download the already available:\n",
    "\n",
    "[Simulation data](https://dataverse.csuc.cat/dataset.xhtml?persistentId=doi:10.34810/data31)\n",
    "\n",
    "This data corresponds to the data used in the publication presenting the SBMOpenMM library ([Link to our article]()). SBMOpenMM has an automatic method to get this data, inside its \"datasets\" container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data command here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store aligned trajectory files\n",
    "folder = 'simulation_data'\n",
    "trajectory_files = []\n",
    "for d in sorted(os.listdir(folder)):\n",
    "    if os.path.isdir(folder+d):\n",
    "        for f in sorted(os.listdir(folder+d)):\n",
    "            if f.endswith('.dcd'):\n",
    "                trajectory_files.append(folder+d+'/'+f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saved the trajectory and energy data at 20 ps for all replicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "\n",
    "We can employ different metrics to represent the simulation data. Typical metrics include the backbone torsion angles, or atom positions or distances. Since we are working with SBMs, we expect that native contact distances will play an essential role in describing the simulation's kinetics. To see if this is true, we compare the performance of three simulation features inside the following notebook:\n",
    "\n",
    "[Feature Selection Notebook]()\n",
    "\n",
    "Here, we can observe that native contacts are an excellent feature to describe the folding simulation of the FoxP1 system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Native contacts\n",
    "\n",
    "We will feature all the trajectories as vectors containing the alpha-carbon (CA) native contact distances. Since our contact file contains all-atom contacts, we first need to define the list of per-residue native contacts and then define these contacts in terms of the alpha carbon indexes, as they appear in the structure file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCAcontacts(AA_sbmModel, residue_index=False):\n",
    "    \"\"\"\n",
    "    Get per-residue native contacts. This function reads an AA SBM class\n",
    "    and returns the per-residue native contacts based on the indexes of the\n",
    "    alpha-carbon atoms in the system. If option residue_index is given then\n",
    "    the function returns the residue indexes instead of the alpha-carbon atoms'\n",
    "    indexes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a set with residue contacts only\n",
    "    residue_contacts = set()\n",
    "    for c in AA_sbmModel.contacts:\n",
    "        residue_contacts.add((c[0].residue.index, c[1].residue.index))\n",
    "        \n",
    "    # Create a map from residue index to CA atom index\n",
    "    # or residue index\n",
    "    CA_atom = {}\n",
    "    for a in AA_sbmModel.atoms:\n",
    "        if a.name == 'CA':\n",
    "            if residue_index:\n",
    "                CA_atom[a.residue.index] = a.residue.index+1\n",
    "            else:\n",
    "                CA_atom[a.residue.index] = a.index+1\n",
    "            \n",
    "    # Define per-residue native contacts based on CA indexes.\n",
    "    ca_contacts = []\n",
    "    \n",
    "    for c in sorted(residue_contacts):\n",
    "        ca_contacts.append((CA_atom[c[0]], CA_atom[c[1]]))\n",
    "        \n",
    "    return np.array(ca_contacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an all-atom SBM (AA-SBM) and use our function to get the list of the alpha-carbon native contacts. Note that when creating the AA-SBM, we use the default_parameters=False option. This option will stop the SBM assignment of parameters, forces, and the creation of the OpenMM system object since we are only interested in reading the contact file information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an SBMOpenMM All-Atom SBM without parameters, forces, and system attributes.\n",
    "structure_file = 'input/FoxP_monomer.pdb'\n",
    "contact_file = 'input/FoxP_monomer.contacts'\n",
    "AA_sbmModel = sbmOpenMM.models.getAllAtomModel(structure_file, contact_file, default_parameters=False)\n",
    "\n",
    "# Get list of per-residue native contacts based on the SBM alpha-carbons indexes.\n",
    "ca_native_contacts = getCAcontacts(AA_sbmModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization\n",
    "\n",
    "Now we use PyEMMA to process our simulation files and convert them into CA native contact distance vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CA native contact distances as the simulation feature\n",
    "ca_native_contacts_feat = pyemma.coordinates.featurizer(structure_file)\n",
    "ca_native_contacts_feat.add_distances(ca_native_contacts, periodic=False)\n",
    "ca_native_contacts_data = pyemma.coordinates.load(trajectory_files, features=ca_native_contacts_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimmensionality reduction\n",
    "\n",
    "To get insight into the folding simulation is highly recommended to reduce the dimensional space to represent the data. A recommended way of doing this is by using the Time-lagged Independent Component Analysis (TICA) method. This method is a linear transformation of the featured vectors that maximize the autocorrelation at a given lag-time. To select the appropriate lag-time for the TICA transformation, we will estimate the number of dimensions necessary to explain the 95% of the kinetic variance using different lag-time* values.\n",
    "\n",
    "*A lag-time in our case is equivalent to the \"dt\" (time of each frame), which is equivalent to 20 ps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of dimensions at a fixed value of kinetic variance (95% default for tica function)\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "# Iterate until a value of 50 lag-times\n",
    "for lag_time in range(1,51):\n",
    "    tica = pyemma.coordinates.tica(ca_native_contacts_data, lag=lag_time)\n",
    "    tica_output = tica.get_output()\n",
    "    tica_concatenated = np.concatenate(tica_output)\n",
    "    ndim = tica_concatenated.shape[1]\n",
    "    X.append(lag_time)\n",
    "    Y.append(ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of dimension as a function of the selected lag time.\n",
    "Xa = np.array(X)*20/1000 # Convert lag-times to ns \n",
    "plt.plot(Xa,Y)\n",
    "plt.xlabel('Lag time [ns]')\n",
    "plt.ylabel('Nbr. of dimensions holding\\n95% of the kinetic variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the TICA dimensions rapidly decrease when increasing the lag-time at which the analysis is carried out. The system only needs two dimensions to explain 95% of the kinetic variance using a lag-time of 0.66 ns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the simulation into TICA space\n",
    "\n",
    "To continue with our analysis, we will employ a lag-time of 33 (0.66ns). First, we estimate the TICA space and then convert all the featured data into TICA coordinates IC1 and IC2. After this, we plot the time progression of each TICA coordinate and their cumulative histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a lag time for TICA calculation\n",
    "lag_time = 33\n",
    "\n",
    "# Calculate TICA at a specfic lag time\n",
    "tica = pyemma.coordinates.tica(ca_native_contacts_data, lag=lag_time)\n",
    "tica_output = tica.get_output()\n",
    "tica_concatenated = np.concatenate(tica_output)\n",
    "ndim = tica_concatenated.shape[1]\n",
    "print('Number of TICA Dimensions at lagtime %s: %s' % (lag_time, ndim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot progression of TICA dimensions along the MD coordinate\n",
    "fig, axes = plt.subplots(ndim, 1, figsize=(12, ndim), sharex=True, sharey=True)\n",
    "x = 0.02 * np.arange(tica_output[0].shape[0])\n",
    "for i, (ax, tic) in enumerate(zip(axes.flat, tica_output[0].T)):\n",
    "    ax.plot(x, tic)\n",
    "    ax.set_ylabel('IC {}'.format(i + 1))\n",
    "    \n",
    "# Plot densities of TICA dimensions\n",
    "fig, axes = plt.subplots(1, 1)\n",
    "pyemma.plots.plot_feature_histograms(\n",
    "    tica_concatenated,\n",
    "    ax=axes,\n",
    "    feature_labels=['IC'+str(i) for i in range(1,ndim+1)],\n",
    "    ylog=True)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We project our simulated data into all possible 2D TICA spaces. Since we only have two TICA dimensions, only one plot is generated. Be careful if the \"tica\" object contains many dimensions because the combinatorics will be huge!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate all 2D combinations of the TICA space and generate a density plot for each one. \n",
    "# Note that if there are too many dimensions the calculation will be huge. Please limit the number of dimensions\n",
    "# generated by the tica method in the above cells (e.g., pyemma.coordinates.tica(ndim=5)).\n",
    "\n",
    "IC = {}\n",
    "for i in range(tica_concatenated.shape[1]):\n",
    "    IC[i] = tica_concatenated[:, i]\n",
    "combinations = list(itertools.combinations(range(tica_concatenated.shape[1]), r=2))\n",
    "fig, axes = plt.subplots(len(combinations), figsize=(7, 5*len(combinations)), sharey=True, sharex=True)\n",
    "print()\n",
    "for i,c in enumerate(combinations):\n",
    "    if len(combinations) <= 1:\n",
    "        pyemma.plots.plot_density(*np.array([IC[c[0]], IC[c[1]]]), ax=axes, logscale=True)\n",
    "        axes.set_xlabel('IC '+str(c[0]+1))\n",
    "        axes.set_ylabel('IC '+str(c[1]+1))\n",
    "    else:\n",
    "        pyemma.plots.plot_density(*np.array([IC[c[0]], IC[c[1]]]), ax=axes[i], logscale=True)\n",
    "        axes[i].set_xlabel('IC '+str(c[0]+1))\n",
    "        axes[i].set_ylabel('IC '+str(c[1]+1))\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster analysis | VAMP2 score\n",
    "\n",
    "Now that we have reduced our data dimensions to only two TICA coordinates, we will construct our MSM. To do this, we need to discretize the space into representative clusters of the data. This clusterization can be done by applying the k-means algorithm to generate representative groups over the TICA space. Since discretizing the trajectory data carries the risk of losing kinetic information and possibly introducing errors in the analysis, we will validate the number of clusters generated by their ability to explain the kinetic data. \n",
    "\n",
    "For the validation, we employ the VAMP-2 score as a heuristic of the kinetic variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of clusters to evaluate\n",
    "n_clustercenters = [5]+list(range(10,101,10))+list(range(120,201,20))+list(range(300,1001,100))\n",
    "\n",
    "# Calculate the VAMP2 score of a MSM calculated with different number of k-means clusters.\n",
    "scores = np.zeros((len(n_clustercenters), 5))\n",
    "for n, k in enumerate(n_clustercenters):\n",
    "    for m in range(5):\n",
    "        with pyemma.util.contexts.settings(show_progress_bars=False):\n",
    "            _cl = pyemma.coordinates.cluster_kmeans(\n",
    "                tica_output, k=k, max_iter=200, stride=50)\n",
    "            _msm = pyemma.msm.estimate_markov_model(_cl.dtrajs, lag_time)\n",
    "            scores[n, m] = _msm.score_cv(\n",
    "                _cl.dtrajs, n=1, score_method='VAMP2', score_k=min(10, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the VAMP2 score vs the number of clusters\n",
    "fig, ax = plt.subplots()\n",
    "lower, upper = pyemma.util.statistics.confidence_interval(scores.T.tolist(), conf=0.9)\n",
    "ax.fill_between(n_clustercenters, lower, upper, alpha=0.3)\n",
    "ax.plot(n_clustercenters, np.mean(scores, axis=1), '-o')\n",
    "ax.semilogx()\n",
    "ax.set_xlabel('Number of cluster centers')\n",
    "ax.set_ylabel('VAMP-2 score')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above result, we will select 1000 clusters to represent the Markov states of our Markov model. The representation is done by assigning to each TICA-projected frame a cluster's index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the number of clusters to build the MSM\n",
    "n_clusters = 1000\n",
    "# Calculate cluster in TICA space using the k-means algorithm\n",
    "cluster = pyemma.coordinates.cluster_kmeans(tica_output, k=n_clusters, max_iter=100, stride=10)\n",
    "dtrajs_concatenated = np.concatenate(cluster.dtrajs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also plot the clusters' location in the 2D TICA space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the k-means clusters into the first and second TICA dimensions\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "pyemma.plots.plot_density(\n",
    "    *tica_concatenated[:, :2].T, ax=ax, cbar=False, alpha=0.3)\n",
    "ax.scatter(*cluster.clustercenters[:, :2].T, s=5, c='C1')\n",
    "ax.set_xlabel('IC 1', fontsize=12)\n",
    "ax.set_ylabel('IC 2', fontsize=12)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implied time scales (ITS)\n",
    "\n",
    "Before moving into the MSM construction, we will validate the lag time selection by doing an implied-time scales analysis. The implied time scales (ITS) are computed from the eigenvalues of the MSM transition matrix. They represent the decorrelation times of the kinetic processes inside the transition matrix.\n",
    "\n",
    "Here we will only consider the five slowest processes' ITSs by plotting them as a function of the selected lag-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the lag times to evaluate (only use 5 eigenvalues)\n",
    "its = pyemma.msm.its(cluster.dtrajs, lags=[ 1, 2, 3, 5, 8, 12, 20, 28, 33, 40, 50], nits=5, errors='bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ITS\n",
    "pyemma.plots.plot_implied_timescales(its, dt=20, units='ps');\n",
    "plt.xlabel('Lag time [ns]', fontsize=12)\n",
    "plt.ylabel('Timescale [ps] ', fontsize=12)\n",
    "print(its.lags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the ITSs become constant at the selected lag time of 0.66ns. At this lag-time, the MSM has only one relevant transition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapman-Kolmogorov test\n",
    "\n",
    "Before moving into the origin of this relevant transition, we will further validate the MSM by running a Chapman-Kolmogorov (CK) test. Since we have only one relevant transition, this test is applied for a two-state MSM. \n",
    "\n",
    "Since the test is very costly memory-wise, we recommend running it in a separate notebook:\n",
    "\n",
    "[Run Chapman-Kolmogorov Notebook](other_notebooks/Chapman_Kolmogorov.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationary distribution and free energy\n",
    "\n",
    "We are ready now to build our MSM for the folding simulation. We employ a lag-time of 33 (0.66 ns), and we use a thousand k-means clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcualte a Bayesian Markov State Model \n",
    "msm = pyemma.msm.bayesian_markov_model(cluster.dtrajs, lag=lag_time, dt_traj='20 ps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the stationary distribution and the free energy for our system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot stationary distribution and free energy\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharex=True, sharey=False)\n",
    "pyemma.plots.plot_contour(\n",
    "    *tica_concatenated[:, :2].T,\n",
    "    msm.pi[dtrajs_concatenated],\n",
    "    ax=axes[0],\n",
    "    mask=True,\n",
    "    cbar_label='stationary distribution')\n",
    "pyemma.plots.plot_free_energy(\n",
    "    *tica_concatenated[:, :2].T,\n",
    "    weights=np.concatenate(msm.trajectory_weights()),\n",
    "    ax=axes[1],\n",
    "    legacy=False)\n",
    "for ax in axes.flat:\n",
    "    ax.set_xlabel('IC 1')\n",
    "axes[0].set_ylabel('IC 2')\n",
    "axes[1].set_ylabel('IC 2')\n",
    "axes[0].set_title('Stationary distribution')\n",
    "axes[1].set_title('Reweighted free energy surface')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system has two clear minima separated by the IC1 coordinate (FoxP1 is a two-state folder). On the other hand, the IC2 coordinate describes dynamical transitions inside each basin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second right eigenvector\n",
    "\n",
    "Since we are interested in the MSM transition matrix's slowest process, we plot its second eigenvector, associated with the slowest process in the simulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvec = msm.eigenvectors_right()\n",
    "fig = plt.figure()\n",
    "fig.tight_layout()\n",
    "i=0\n",
    "pyemma.plots.plot_contour(\n",
    "        *tica_concatenated[:, :2].T,\n",
    "        eigvec[dtrajs_concatenated, i+1],\n",
    "        cmap='PiYG',\n",
    "        cbar_label='Second right eigenvector of the MSM transtion matrix',\n",
    "        mask=True)\n",
    "plt.xlabel('IC 1', fontsize=12)\n",
    "plt.ylabel('IC 2', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the slowest transition happens between the two free energy minima. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCCA++ clustering into 2 states\n",
    "\n",
    "By using the above information, we can now divide our simulation into two kinetically-relevant macrostates. We do this by applying the PCCA++ clustering method to assign each configuration to a specific metastable state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nstates = 2\n",
    "msm.pcca(nstates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize this transition's location in the 2D TICA space, we plot a crisp assignment of the macrostates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot crisp partitioning of metastable states\n",
    "metastable_traj = msm.metastable_assignments[dtrajs_concatenated]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "_, _, misc = pyemma.plots.plot_state_map(\n",
    "    *tica_concatenated[:, :2].T, metastable_traj, ax=ax)\n",
    "ax.set_xlabel('IC 1')\n",
    "ax.set_ylabel('IC 2')\n",
    "misc['cbar'].set_ticklabels([r'$\\mathcal{S}_%d$' % (i + 1)\n",
    "                             for i in range(nstates)])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radius of gyration\n",
    "\n",
    "To know which configurations are associated with each macrostate, we plot the radius of gyration (ROG) distribution of each basin.\n",
    "\n",
    "However, since reading into memory all trajectories is very costly, we recommend making the calculations in a separate notebook:\n",
    "\n",
    "[Calculate radius of gyration here](other_notebooks/radiusOfGyration.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load radius of gyration result file\n",
    "rg_concatenated = np.load('output/radiusOfGyration.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first take a look at the ROG distribution in the 2D TICA space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "pyemma.plots.plot_contour(\n",
    "    *tica_concatenated[:, :2].T,\n",
    "    np.ravel(rg_concatenated),\n",
    "    ax=ax,\n",
    "    mask=True,\n",
    "    cbar_label=r'Radius of Gyration / nm')\n",
    "ax.set_xlabel('IC 1', fontsize=12)\n",
    "ax.set_ylabel('IC 2', fontsize=12)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that when moving from one basing to the other there is an increase in ROG. Now we select the values for each of the macrostates, and plot their respective ROG distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROG distribution for each macrostate\n",
    "rg_traj = np.ravel(rg_concatenated)\n",
    "labels = ['Folded', 'Unfolded']\n",
    "color = ['purple', 'y']\n",
    "fig, ax = plt.subplots()\n",
    "# iterate over macrostates\n",
    "for num, metastable_set in enumerate(msm.pcca(2).metastable_sets):\n",
    "    traj_indices = np.where(np.isin(dtrajs_concatenated, metastable_set))[0]\n",
    "    # plot histogram distribution\n",
    "    hist = sns.histplot(rg_traj[traj_indices], color=color[num], label=labels[num], kde=True)\n",
    "    # plot average ROG value\n",
    "    ax.axvline(rg_traj[traj_indices].mean(), c=color[num], lw=0.8, ls='--')\n",
    "    \n",
    "ax.legend(fontsize=12)\n",
    "ax.set_xlabel(r'Radius of Gyration [nm]', fontsize=12)\n",
    "ax.set_ylabel(r'MD frames', fontsize=12)\n",
    "plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above result, we see that the left basin is associated with the folded state and that the right basin with unfolded one. We can now calculate the free energies of these basins as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('state\\tÏ€\\t\\tG [kT]')\n",
    "for i, s in enumerate(msm.metastable_sets):\n",
    "    p = msm.pi[s].sum()\n",
    "    print('{}\\t{:f}\\t{:f}'.format(i + 1, p, -np.log(p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unfolded basin has a higher probability of being visited than the folded one. These probabilities say that our temperature is slightly above the actual folding temperature for this AA-SBM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folding transition state\n",
    "\n",
    "Finally, we would like to locate the transition state surface for the folding transition. We do this by applying Transition Path Theory to calculate the commitor function of the transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the comittor function for the U -> F transition\n",
    "start, final = 1, 0\n",
    "A = msm.metastable_sets[start]\n",
    "B = msm.metastable_sets[final]\n",
    "flux = pyemma.msm.tpt(msm, A, B)\n",
    "\n",
    "cg, cgflux = flux.coarse_grain(msm.metastable_sets)\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "fig, ax, contour = pyemma.plots.plot_contour(\n",
    "                   *tica_concatenated[:, :2].T,\n",
    "                   flux.committor[dtrajs_concatenated],\n",
    "                   cmap='brg',\n",
    "                   ax=ax,\n",
    "                   mask=True,\n",
    "                   cbar_label=r'Committor of Unfolded $\\to$ Folded')\n",
    "\n",
    "ax.set_xlabel('IC 1', fontsize=12)\n",
    "ax.set_ylabel('IC 2', fontsize=12)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By definition, the commitor function is 0.5 at the TS; therefore, the red line in the above plot represents the folding process' TS region. Having this definition, we can gather configurations near or at the TS region to query them for the FoxP1 folding mechanism. We define a TICA-space distance to the TS (TS_distance) and pick all configurations as close to the TS region. \n",
    "\n",
    "In practice, we use the TS line (red line) defined in the above TST contour plot to determine the TS location numerically. Then we calculate the distance of each configuration to all the line points. If the smaller of these distances is less or equal to the TS distance threshold, then the configuration is considered in the TS region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all points for the TS line\n",
    "p1 = contour['mappable'].collections[1].get_paths()[0]\n",
    "v1 = p1.vertices\n",
    "x1 = v1[:,0]\n",
    "y1 = v1[:,1]\n",
    "ts_location = np.array([x1,y1]).T\n",
    "\n",
    "# Calculate TS membership for all trajectories\n",
    "TS_distance = 0.02 \n",
    "TS_state_frames = {}\n",
    "for i,tica_traj in enumerate(tica_output):\n",
    "    # Distance of the configurations' TICA coordinates to the TS line\n",
    "    diff = tica_traj - ts_location[:, np.newaxis] # Broadcast differences\n",
    "    tsd = np.min(np.linalg.norm(diff, axis=2), axis=0)\n",
    "    # Only get configurations inside the TS region\n",
    "    TS_state_frames[i] = np.argwhere(tsd < TS_distance).T[0]\n",
    "    \n",
    "# Save TS frames indexes into a file\n",
    "for i in TS_state_frames:\n",
    "    with open('output/ts_frames'+str(i+1).zfill(2)+'.npy', 'w') as ts_frames_file:\n",
    "        np.savetxt(ts_frames_file, TS_state_frames[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we need to load the full trajectories to access the TS surface frames, we have saved each trajectory's ts frame's indexes into different files ('output/ts_frames_x_.json'). With this information, we now open a separate notebook to create a single trajectory containing all the TS frames:\n",
    "\n",
    "[Create TS trajectory notebook](other_notebooks/getTStrajectory.ipynb)\n",
    "\n",
    "After the trajectory has been created, we loaded it here and continue with the analysis. \n",
    "\n",
    "We continue by reading the TS trajectory file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_traj_file = 'output/ts_trajectory.dcd'\n",
    "ts_trajectory = md.load(ts_traj_file, top=structure_file)\n",
    "print(ts_trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of looking at each configuration in the TS idependently, we will calculate the probability of native contact formation at the TS. For this we create a function that generates the contact probability matrix, by counting the formation of each native contact in each frame in the TS configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContactProbabilityMatrix(traj_files, structure_file, contact_file):\n",
    "    \"\"\"\n",
    "    Calculates the alpha carbon native contact formation probability for a \n",
    "    set of trajectory files. The native contact definition is read from a \n",
    "    contact file. A contact is considered formed if the distance is lower \n",
    "    than 1.05 times the native contact's equilibrium value.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    traj_files : str or list or tuple\n",
    "        The paths to the trajectory files. The upper matrix is filled with the contact map \n",
    "        and the lower matrix is filled with the information derived from the trajectory files.\n",
    "    structure_file : str\n",
    "        Path to the PDB structure file.\n",
    "    contact_file : str\n",
    "        Path to the native contact file.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    M : np.ndarray\n",
    "        Native contact formation probability matrix \n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(traj_files, str):\n",
    "        traj_files = [traj_files]\n",
    "    \n",
    "    # Read forcefield parameters to extract native contacts\n",
    "    AA_sbmModel = sbmOpenMM.models.getAllAtomModel(structure_file, contact_file, default_parameters=False)\n",
    "    \n",
    "    # Calculate native contacts\n",
    "    ca_native_contacts = getCAcontacts(AA_sbmModel)\n",
    "    \n",
    "    # Calculate native contacts\n",
    "    native = md.load(structure_file)\n",
    "    native_distances = md.compute_distances(native, ca_native_contacts)\n",
    "    \n",
    "    # Calculate the probability of contact formation\n",
    "    nc_count = np.zeros(native_distances.shape[1])\n",
    "    N = 0\n",
    "    for traj_file in traj_files:\n",
    "        traj = md.load(traj_file, top=structure_file)\n",
    "        traj_distances = md.compute_distances(traj, ca_native_contacts)\n",
    "        nc_count += np.sum(np.where(traj_distances <= native_distances*1.05, 1.0, 0), axis=0)\n",
    "        N += traj_distances.shape[0]\n",
    "    probability = nc_count/N\n",
    "        \n",
    "    # Create matrix\n",
    "    residue_native_contacts = getCAcontacts(AA_sbmModel, residue_index=True)\n",
    "    n_res = AA_sbmModel.topology.getNumResidues()\n",
    "    M = np.zeros((n_res, n_res))\n",
    "        \n",
    "    for i,p in enumerate(probability):\n",
    "        r = residue_native_contacts[i]\n",
    "        M[r[0]-1][r[1]-1] = p\n",
    "        M[r[1]-1][r[0]-1] = 1.0\n",
    "    M[M == 0 ] = np.nan\n",
    "                \n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the contact probability matrix and plot it together with the native contacts of FoxP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcualate contact probability formation at the TS\n",
    "M = getContactProbabilityMatrix(ts_traj_file, structure_file, contact_file)\n",
    "\n",
    "# Plot native contacts and native contact formation probability\n",
    "plt.matshow(M, cmap='hot_r', vmin=0, vmax=1.0, origin='lower')\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "# Plot an identity line to separate the upper and lower half-matrices\n",
    "plt.plot([0,87],[0,87], c='k', ls='-', lw=0.5)\n",
    "cbar.set_label('Contact formation probability', size=12)\n",
    "\n",
    "# Plot residue numbers every ten. \n",
    "xticks = plt.xticks(np.insert(np.arange(9, 87, 10), 0, 0), np.insert(np.arange(10, 88, 10), 0, 1))\n",
    "yticks = plt.yticks(np.insert(np.arange(9, 87, 10), 0, 0), np.insert(np.arange(10, 88, 10), 0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that, at the TS, contacts made by the beta-sheets are still formed before going to the unfolded state."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
